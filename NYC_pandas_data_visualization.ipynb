{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ace39e7-b738-416f-8284-d1dac1820b16",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Intro\n",
    "\n",
    "This practice is done thanks to *Data Science Lab: Process And Methods* course that is tought in [Data Science and Engineering](https://didattica.polito.it/laurea_magistrale/data_science/en/home) program in [Politecnico di Torino](https://www.polito.it/index.php?lang=it) for laboratory purpose during the 2022/2023 semester. The aim is making data exploration analysis on *New York - Point of Interest* real-world dataset ([download](https://github.com/dbdmg/data-science-lab/raw/master/datasets/NYC_POIs.zip)) by using [Pandas data analysis library](https://pandas.pydata.org/). Also Numpy and Matplotlib libraries are used.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7da3a9-3813-414b-b377-c68b9ea5fc8c",
   "metadata": {},
   "source": [
    "# Datasets\n",
    "There are 2 databases we will work with:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3274ea-7ad0-4b01-964f-f898e2db8785",
   "metadata": {},
   "source": [
    "### 1. **New York Point of Interest** dataset\n",
    "This dataset shows the sub-sample of point of interests (POI) placed in the city of New York. Each row demonsrates a POI with its **coordinates** and the **category** to which it belongs to. Each category has its own column in which **types** of POIs are written. Fields in the dataset are:\n",
    "1. _@id_: a unique id for each point of interest.\n",
    "1. _@lat_: latitude coordinate of the POI in decimal degrees.\n",
    "1. _@lon_: longitude coordinate of the POI in decimal degrees.\n",
    "1. _amenity_: if the POI category is amenity its type is reported in this field.\n",
    "1. _name_: is not used\n",
    "1. _shop_: if the POI category is shop its type is reported in this field.\n",
    "1. _public_transport_: if the POI category is public transport its type is reported in this field.\n",
    "1. _highway_: if the POI category is highway its type is reported in this field.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0581f649-30d7-4713-a134-e498ea79992a",
   "metadata": {},
   "source": [
    "### 2. **The New York City municipality POIs** dataset\n",
    "Some of POIs belong to NYC municipality. In order to identify them, a further file is provided. This file contains only **ID**s which corresponds to NYC Municipality POIs\n",
    "\n",
    "*NOTE*: The map of the New York municipality is provided as well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c022b3-232a-4dc0-80a3-a135050aa6b9",
   "metadata": {},
   "source": [
    "# Exercises and Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf56762-2ec4-43a9-a71e-cd8ed7f59f5a",
   "metadata": {},
   "source": [
    "**1.** Loading datasets and filtering the ones that belong NYC municipality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861c765b-3870-4ca0-b468-6d1d177f4bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings #not show warnings as output\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036b48c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the csv file (sep='\\t' is used since the files are tab seperated)\n",
    "df = pd.read_csv(\"C:/Users/Koparan/Desktop/DataPolito/DataScienceLab/laboratory/solutions/lab5/pois_all_info\",\n",
    "                sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d334dd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exploring data fields with their data types in addition to null values\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdcb063",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading NYC municipality POIs file\n",
    "#header=None because this file does not contain header. \n",
    "#We need to prevent getting the first ID as header\n",
    "ny_id = pd.read_csv(\"C:/Users/Koparan/Desktop/DataPolito/DataScienceLab/laboratory/solutions/lab5/ny_municipality_pois_id.csv\",\n",
    "                    sep='\\t',\n",
    "                    header=None)\n",
    "ny_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2c1e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing the column name as @id in the NYC municipality like the ID column in the main file\n",
    "ny_id.set_axis([df.columns[0]],axis=1,inplace=True)\n",
    "ny_id.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdff6b51",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "- We can filter municipality POIs by using 'merge' function.\n",
    "- The column name we merge must be the same.\n",
    "- how='inner' is used because we want to work with the IDs that must be \n",
    "belong to both datasets.\n",
    "'''\n",
    "nydf = pd.merge(df,ny_id,on=df.columns[0],how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5685fca0-ae89-4fa6-8dd2-1fbf219d26bf",
   "metadata": {},
   "source": [
    "**2.** Analysing the distribution of POI types for each POI category(*amenity*, *shop*, *public_transport*, *highway*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5397dbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting categories as list will make the following analysis easier\n",
    "#first we eliminate the columns with contains '@' e.g. '@lat'\n",
    "categories = nydf[nydf.columns.drop(list(nydf.filter(regex='@')))]\n",
    "#then, we eliminate name columns that will not be useful for our study\n",
    "categories = categories.drop(columns=['name'])\n",
    "categories = list(categories.columns)\n",
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d961f9c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create a dict to collect each category and its types with different key values\n",
    "dfs = {}\n",
    "#fill the dict with values based on key values\n",
    "for cat in categories:\n",
    "    dfs['df_'+cat] = nydf.loc[:,['@type',cat]]\n",
    "#clear NaN values which corresponds to different rows for each POI type\n",
    "for k in dfs:\n",
    "    dfs[k].dropna(subset=[dfs[k].columns[1]],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d3a115",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to visualize effectively, get first 80% of POI names. We will use this function for every POI\n",
    "def get_top_perc(series, perc_value=0.8):\n",
    "    perc = series.cumsum() / series.sum()\n",
    "    arg = (perc>perc_value).values.argmax()\n",
    "    return series.iloc[:arg+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ad4142",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create a figure and add 4 subplot for each category. We will have 4 histogram\n",
    "for col in categories:\n",
    "    p = .8 #threshold value\n",
    "    valc = dfs['df_'+col].iloc[:,1].value_counts()\n",
    "    valf = get_top_perc(valc,p)\n",
    "    fig,ax = plt.subplots() #create a figure\n",
    "    valf.plot(kind='bar',ax=ax) #bar=histogram\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=90) #rotate the x axis names as vertical\n",
    "    fig.suptitle(f\"Top {p*100:.0f}% points in the category: {col}\") #title for selected POI in the loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df684dba-1f8d-48da-a3ed-47154df2b343",
   "metadata": {},
   "source": [
    "**3.** Show the POIs in New York map with scatter plot. For each POI type, select a different colour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f61605",
   "metadata": {},
   "outputs": [],
   "source": [
    "#location and types\n",
    "dfs = {}\n",
    "for cat in categories:\n",
    "    dfs['df_'+cat] = nydf.loc[:,['@lat','@lon',cat]]\n",
    "#delete NaN values for each type\n",
    "for k in dfs:\n",
    "    dfs[k].dropna(subset=[dfs[k].columns[2]],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec43dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib.cm import get_cmap\n",
    "\n",
    "class Map:\n",
    "    def __init__(self,df):\n",
    "        #this dataframe will be used for the map. We relate it with the class object\n",
    "        self.pois_df = df\n",
    "        #to scale the map, we get max and min values for vertical and horizontal axes.\n",
    "        self.lat_min = df['@lat'].min()\n",
    "        self.lat_max = df['@lat'].max()\n",
    "        self.long_min = df['@lon'].min()\n",
    "        self.long_max = df['@lon'].max()\n",
    "    def plot_map(self):\n",
    "        \"\"\"Display the image with NY map and return the Axes object\"\"\"\n",
    "        fig, ax = plt.subplots()\n",
    "        nyc_img = plt.imread(\"C:/Users/Koparan/Desktop/DataPolito/DataScienceLab/laboratory/solutions/lab5/New_York_City_Map.PNG\")\n",
    "        ax.imshow(nyc_img, zorder=0, extent = [self.long_min,\n",
    "                                               self.long_max,\n",
    "                                               self.lat_min,\n",
    "                                               self.lat_max])\n",
    "        ax.grid(False)\n",
    "        return ax\n",
    "    def plot_pois(self,ax,category,mask):\n",
    "        \"\"\"Plot data on specified Axis\"\"\"\n",
    "        df = self.pois_df.loc[mask]\n",
    "        types = df[category].unique()\n",
    "        cmap = get_cmap('viridis')\n",
    "        colors = cmap(np.linspace(0,1,types.size))\n",
    "        for i,t in enumerate(types):\n",
    "            df_t = df.loc[df[category]==t]\n",
    "            c = [colors[i]]*df_t.shape[0]\n",
    "            df_t.plot.scatter(x='@lon',y='@lat',\n",
    "                             ax = ax,\n",
    "                             c = c,\n",
    "                             alpha=.6,\n",
    "                             label=t)\n",
    "        ax.legend()\n",
    "        ax.grid(False)\n",
    "        return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6129823e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the function is defined for any POI type ('column'). \n",
    "def show_category_on_map(df, column, perc_value):\n",
    "    counts = df[column].value_counts()\n",
    "    top_freq = get_top_perc(counts, perc_value)\n",
    "    np_map=Map(df)\n",
    "    \n",
    "    ax = np_map.plot_map()\n",
    "    mask = df[column].isin(top_freq.index) #this masking get only values which match the 80% of the values from the selected POI type column \n",
    "    np_map.plot_pois(ax,column,mask)\n",
    "\n",
    "#you can use any POI type here. I choose amenity to illustrate\n",
    "show_category_on_map(dfs['df_amenity'],'amenity',.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026b5999-9e6e-4f0f-b63d-555915fa82be",
   "metadata": {},
   "source": [
    "**4.** From the New York map, get grids and numerate them. Then, assign each POI to the grid that belongs to based on its coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71aa3a39-cd9c-4250-9d21-d7dc7aa9af84",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Assign():\n",
    "    def __init__(self, df, dfs):\n",
    "        \"\"\"same with the Map class above\"\"\"\n",
    "        self.df = df\n",
    "        self.min_lon = df.loc[:,'@lon'].min()\n",
    "        self.max_lon = df.loc[:,'@lon'].max()\n",
    "        self.min_lat = df.loc[:,'@lat'].min()\n",
    "        self.max_lat = df.loc[:,'@lat'].max()\n",
    "    def gridMap(self):\n",
    "        \"\"\"same with the Map class above except \"ax.grid(True)\"\"\"\n",
    "        fig, ax = plt.subplots()\n",
    "        nymap = plt.imread(\"C:/Users/Koparan/Desktop/DataPolito/DataScienceLab/laboratory/solutions/lab5/New_York_City_Map.PNG\")\n",
    "        plt.imshow(nymap, zorder=0, extent = [self.min_lon,\n",
    "                                              self.max_lon,\n",
    "                                              self.min_lat,\n",
    "                                              self.max_lat])\n",
    "        ax.grid(True)\n",
    "        return ax\n",
    "    def getGridLoc(self):\n",
    "        \"\"\"getting the locations of grid intersections as x and y axes\"\"\"\n",
    "        ax = self.gridMap()\n",
    "        self.xGridLocs = list(ax.get_xticks())\n",
    "        self.yGridLocs = list(ax.get_yticks())\n",
    "        return self.xGridLocs, self.yGridLocs\n",
    "    def zoneByLoc(self):\n",
    "        \"\"\"create a dataframe in which columns are X ticks while rows are Y ticks of the map.\n",
    "        values are just numbers that show which ticks correspond to which zone number\"\"\"\n",
    "        self.getGridLoc()\n",
    "        totalZone = (len(self.xGridLocs)-1)*(len(self.yGridLocs)-1)\n",
    "        s = np.array(range(1,totalZone+1)).reshape(len(self.yGridLocs)-1,\n",
    "                                               len(self.xGridLocs)-1)\n",
    "        #for x and y, less than or equal values are assigned to this node\n",
    "        self.zones = pd.DataFrame(data=s,\n",
    "                              index=self.yGridLocs[1:],\n",
    "                              columns=self.xGridLocs[1:])\n",
    "        return self.zones\n",
    "    def getNYid(self,nyids):\n",
    "        \"\"\"This is used to eliminate rows that not belong to New York coordinates from the dataframe\"\"\"\n",
    "        nyids.set_axis([self.df.columns[0]],axis=1,inplace=True)\n",
    "        self.nydf = pd.merge(self.df,nyids, on=df.columns[0],how='inner')\n",
    "        self.nydf.dropna(axis=0, how='all', subset=categories, inplace=True)\n",
    "        return self.nydf\n",
    "    def assignZone(self):\n",
    "        \"\"\"We assign each row in the dataframe to a cell in the grid map.\n",
    "        First, we create a column 'cell_id' in the dataframe to assign related number\"\"\"\n",
    "        self.nydf['cell_id'] = 0\n",
    "        zones = self.zoneByLoc()\n",
    "        lats = zones.index \n",
    "        lons = zones.columns\n",
    "        for i in self.nydf.index:\n",
    "            lat = self.nydf.loc[i,'@lat']\n",
    "            lon = self.nydf.loc[i,'@lon']\n",
    "            for a in lats:\n",
    "                for b in lons:\n",
    "                    if lat<a and lon<b:\n",
    "                        self.nydf.loc[i,'cell_id']=zones.loc[a,b]\n",
    "                        break\n",
    "                else: #this 'else' block is executed if the 'for' loop is not terminated with 'break' statement\n",
    "                    continue\n",
    "                break \n",
    "        return self.nydf\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44884c2c-4616-484d-a9e7-fd8a90218417",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an object with Assign class\n",
    "c = Assign(nydf, dfs)\n",
    "#execute needed methods in class to obtain a DataFrame that contain also cell_id for each row\n",
    "c.zoneByLoc()\n",
    "c.getNYid(ny_id)\n",
    "celldf = c.assignZone()\n",
    "celldf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fbdb7d-65df-45e3-9db3-42d5f5ffd2ee",
   "metadata": {
    "tags": []
   },
   "source": [
    "**5.** Identify how many times a POI type is contained in each cell, for each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5cd06b-a986-4099-b397-4504a0e0263f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#the cell_id values which are also grids will be index values\n",
    "ind = sorted(celldf.cell_id.unique())\n",
    "#we will create a pivot table in which grids are index and POI types are columns \n",
    "pivot = pd.DataFrame(index = ind)\n",
    "for i in categories:\n",
    "    cellpoi = celldf[[i,'cell_id']]\n",
    "    cellpoi.dropna(subset=[i],inplace=True)\n",
    "    a = cellpoi['cell_id'].value_counts()\n",
    "    #there will be no integration problem since index values are matches\n",
    "    pivot[i] = a\n",
    "print(pivot)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fa41a1-a4f8-49ee-80e1-b127456f018c",
   "metadata": {},
   "source": [
    "**6.** Examine the correlation between POI types 'amenity' and 'shop' based on cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fa60e8-6cac-47a4-afd3-265ec784bc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function creates a pivot table in which 'cell_id' is index and POI names are columns for selected POI type\n",
    "def getCount4Zone(df, column, perc=.6):\n",
    "    counts = df[column].value_counts()\n",
    "    percentage = counts.cumsum() / counts.sum()\n",
    "    arg = (percentage>perc).argmax()\n",
    "    names = counts.index[:arg+1]\n",
    "    mask = df[column].isin(names)\n",
    "    df2 = df.loc[mask]\n",
    "    pivot = df2.pivot_table(values='@lat',\n",
    "                        index='cell_id',\n",
    "                        columns=column,\n",
    "                        aggfunc = 'count',\n",
    "                        fill_value = 0)\n",
    "                        \n",
    "    return pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa19500-cc0e-4d02-9cb6-ad05a7a24ef3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create 2 different pivot tables for 'amenity' and 'shop'\n",
    "amedf = getCount4Zone(celldf,'amenity')\n",
    "shopdf = getCount4Zone(celldf,'shop')\n",
    "#concatenate these pivot tables into one\n",
    "final_df = pd.concat([amedf,shopdf], axis=1)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832a3351-3a22-4dc1-9baa-2413bf881a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the correlation between columns\n",
    "final_corr = final_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93e3c54-47ad-4c44-9440-73bbc8b41f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting heatmap of correlation\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(final_corr)\n",
    "ax.set_xticks(np.arange(final_corr.columns.size))\n",
    "ax.set_yticks(np.arange(final_corr.columns.size))\n",
    "ax.set_xticklabels(final_corr)\n",
    "ax.set_yticklabels(final_corr)\n",
    "plt.setp(ax.get_xticklabels(),rotation=90, ha = 'right', va='center',\n",
    "        rotation_mode='anchor')\n",
    "cbar = ax.figure.colorbar(im, ax=ax)\n",
    "_ = cbar.ax.set_ylabel('pearson correlation', rotation=-90, va='bottom')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6e2a5a-5f74-4436-b776-34af194fb9d9",
   "metadata": {},
   "source": [
    "# -The End- #"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
